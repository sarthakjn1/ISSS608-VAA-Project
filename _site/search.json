[
  {
    "objectID": "Project/Investigations.html",
    "href": "Project/Investigations.html",
    "title": "Investigations",
    "section": "",
    "text": "sf: Handles simple features (spatial vector data) in R.\nlwgeom: Extends sf with additional geometric operations.\nunits: Manages unit-aware vectors in R.\nmaps: Provides map data for plotting.\ndplyr: Efficient data manipulation and transformation.\ntidyverse: Collection of R packages for data science (includes dplyr, ggplot2, etc.).\nlubridate: Simplifies date and time manipulation.\njsonlite: Parses and generates JSON data.\nhttr: Facilitates working with URLs and HTTP.\nggplot2: Creates elegant data visualizations.\ntmap: Thematic maps for spatial data.\nleaflet: Interactive maps using the Leaflet JavaScript library.\nviridis: Color scales for scientific data.\nplotly: Interactive graphing library.\nggraph: Extends ggplot2 for graph visualization.\ngganimate: Animates ggplot2 plots.\ngifski: Renders animations to GIFs.\nggrepel: Prevents overlapping text labels in ggplot2.\nigraph: Network analysis and visualization.\ntidygraph: Tidy API for network data.\nvisNetwork: Interactive network visualization.\ngraphlayouts: Layout algorithms for network visualization.\n\n\n# Load necessary R packages using pacman\npacman::p_load(\n  # Spatial Data\n  sf, lwgeom, units, maps,\n  \n  # Data Manipulation\n  dplyr, tidyverse, lubridate, jsonlite, httr,\n  \n  # Visualization\n  ggplot2, tmap, leaflet, viridis, plotly, ggraph, gganimate, gifski, ggrepel,\n  \n  # Network Analysis\n  igraph, tidygraph, visNetwork, graphlayouts\n)"
  },
  {
    "objectID": "Project/Investigations.html#loading-r-packages",
    "href": "Project/Investigations.html#loading-r-packages",
    "title": "Investigations",
    "section": "",
    "text": "sf: Handles simple features (spatial vector data) in R.\nlwgeom: Extends sf with additional geometric operations.\nunits: Manages unit-aware vectors in R.\nmaps: Provides map data for plotting.\ndplyr: Efficient data manipulation and transformation.\ntidyverse: Collection of R packages for data science (includes dplyr, ggplot2, etc.).\nlubridate: Simplifies date and time manipulation.\njsonlite: Parses and generates JSON data.\nhttr: Facilitates working with URLs and HTTP.\nggplot2: Creates elegant data visualizations.\ntmap: Thematic maps for spatial data.\nleaflet: Interactive maps using the Leaflet JavaScript library.\nviridis: Color scales for scientific data.\nplotly: Interactive graphing library.\nggraph: Extends ggplot2 for graph visualization.\ngganimate: Animates ggplot2 plots.\ngifski: Renders animations to GIFs.\nggrepel: Prevents overlapping text labels in ggplot2.\nigraph: Network analysis and visualization.\ntidygraph: Tidy API for network data.\nvisNetwork: Interactive network visualization.\ngraphlayouts: Layout algorithms for network visualization.\n\n\n# Load necessary R packages using pacman\npacman::p_load(\n  # Spatial Data\n  sf, lwgeom, units, maps,\n  \n  # Data Manipulation\n  dplyr, tidyverse, lubridate, jsonlite, httr,\n  \n  # Visualization\n  ggplot2, tmap, leaflet, viridis, plotly, ggraph, gganimate, gifski, ggrepel,\n  \n  # Network Analysis\n  igraph, tidygraph, visNetwork, graphlayouts\n)"
  },
  {
    "objectID": "Project/Investigations.html#loading-the-data",
    "href": "Project/Investigations.html#loading-the-data",
    "title": "Investigations",
    "section": "Loading the Data",
    "text": "Loading the Data\nLoading the mc2 json data which is a directed multigraph consisting of nodes containing entities and edges containing relationships\n\njson_data &lt;- fromJSON(\"data/mc2.json\")\n\n\nLinksNodesExtracting Necessary Features\n\n\nIn this section, we will prepare our links dataset\n\n\nShow the code\nlinks_df &lt;- as_tibble(json_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type),\n         date =  date,\n         time =  as.POSIXct(time, format=\"%Y-%m-%dT%H:%M:%OS\", tz=\"UTC\"),\n         ping_date = as.Date(as.POSIXct(time, format=\"%Y-%m-%dT%H:%M:%OS\", tz=\"UTC\"))) %&gt;%\n  select(type, time, dwell, source, target, date, ping_date)\n\n\nmc2_links &lt;- links_df%&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n(), .groups = 'drop') %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\nglimpse(links_df)\n\n\nRows: 271,643\nColumns: 7\n$ type      &lt;chr&gt; \"Event.TransportEvent.TransponderPing\", \"Event.TransportEven…\n$ time      &lt;dttm&gt; 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09-28 04:31:…\n$ dwell     &lt;dbl&gt; 115074.79, 412706.32, 286092.88, 327623.95, 243225.35, 10956…\n$ source    &lt;chr&gt; \"City of Haacklee\", \"City of Haacklee\", \"City of Haacklee\", …\n$ target    &lt;chr&gt; \"perchplundererbc0\", \"perchplundererbc0\", \"perchplundererbc0…\n$ date      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ping_date &lt;date&gt; 2035-09-16, 2035-09-20, 2035-09-28, 2035-10-04, 2035-10-15,…\n\n\n\n\nIn this section, we will prepare our nodes dataset\n\n\nShow the code\n# Convert nodes to tibble, modify variable types, and select required columns\nnodes_df &lt;- as_tibble(json_data$nodes) %&gt;%\n  mutate(\n    type_original = type,\n    id = as.character(id), \n    type = as.character(type),\n    type = case_when(\n      type %in% c(\"Entity.Vessel.CargoVessel\", \"Entity.Vessel.Ferry.Cargo\", \"Entity.Vessel.FishingVessel\") ~ \"Entity.Vessel\",\n      TRUE ~ type\n    ),\n    tonnage = as.numeric(as.character(tonnage)),\n    length_overall = as.numeric(as.character(length_overall)), \n    Activities = as.character(Activities), \n    fish_species_present, \n    kind = as.character(kind), \n    flag_country = as.character(flag_country),\n    company = as.character(company),\n    name = as.character(name),\n    Name = as.character(Name)) %&gt;%\n  select(id, date, type,type_original, qty_tons, name, Name, company, flag_country, Activities, tonnage, length_overall, fish_species_present, kind)\n\n\nglimpse(nodes_df)\n\n\nRows: 5,637\nColumns: 14\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ date                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ type_original        &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n$ tonnage              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe save our processed data into .rds data format files using the write_rds() of readr package. The output file is saved in rds sub-folder. We do this to reduce the loading time and more importantly, we can avoid uploading the large raw files onto GitHub.\n\n\n\nwrite_rds(links_df, \"data/rds/links_df.rds\")\nlinks_df &lt;- read_rds(\"data/rds/links_df.rds\")\n\nwrite_rds(mc2_links, \"data/rds/mc2_links.rds\")\nmc2_links &lt;- read_rds(\"data/rds/mc2_links.rds\")\n\nwrite_rds(nodes_df, \"data/rds/nodes_df.rds\")\nnodes_df &lt;- read_rds(\"data/rds/nodes_df.rds\")\n\n\n\nIn this section, we will extract out seperate datasets from our nodes and links datasets\n\nvessels_df &lt;- nodes_df %&gt;%\n  filter(type == \"Entity.Vessel\") %&gt;%\n  select(id, Name, company, flag_country, type) %&gt;%\n  mutate(type = sub(\"Entity.Vessel.\", \"\", type))\ndelivery_report_df &lt;- nodes_df %&gt;% \n  filter(type == \"Entity.Document.DeliveryReport\")  %&gt;% \n  rename(cargo_id = id)%&gt;% \n  select(qty_tons,date,cargo_id)\nfish_df &lt;- nodes_df %&gt;% \n  filter(type == \"Entity.Commodity.Fish\") %&gt;% \n  rename(fish_name = name)\ncity_df &lt;- nodes_df %&gt;% \n  filter(type == \"Entity.Location.City\")%&gt;% \n  rename(city_name = Name)\nlocations_df &lt;- nodes_df %&gt;% \n  filter(type == \"Entity.Location.City\"| type==\"Entity.Location.Point\"| type==\"Entity.Location.Region\") %&gt;% \n  rename(location_name = Name)%&gt;% \nselect(id,location_name)\nharbor_report_df &lt;- links_df %&gt;% \n  filter(type == \"Event.HarborReport\")  %&gt;% \n  select(date,source,target)\ntransponder_ping_df &lt;- links_df %&gt;% \n  filter(type == \"Event.TransportEvent.TransponderPing\") %&gt;% \n  select(time,dwell,source,target,ping_date)\ntransactions_df &lt;- links_df %&gt;% \n  filter(type == \"Event.Transaction\") %&gt;% \n  select(date,source,target)\nfishing_grounds_df &lt;- nodes_df %&gt;% \n  filter(kind == \"Fishing Ground\"|kind == \"Ecological Preserve\") %&gt;% \n  select(id,Name,kind,fish_species_present)"
  },
  {
    "objectID": "Project/Investigations.html#data-cleaning",
    "href": "Project/Investigations.html#data-cleaning",
    "title": "Investigations",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nLinksNodesGeographical Information\n\n\nWe discovered that the columns “type,” “source,” and “target” are complete, containing no missing values. Conversely, the columns “time,” “dwell,” “date,” and “ping_date” exhibit numerous missing values. This outcome is anticipated since these columns exclusively hold data for specific categories.\n\n# Check for columns with missing values\ncolSums(is.na(links_df))\n\n     type      time     dwell    source    target      date ping_date \n        0     13101     13101         0         0    258542     13101 \n\n\n\n\nShow the code\nsummary(links_df)\n\n\n     type                time                            dwell         \n Length:271643      Min.   :2035-02-01 00:00:00.00   Min.   :       0  \n Class :character   1st Qu.:2035-04-17 13:33:02.35   1st Qu.:    4695  \n Mode  :character   Median :2035-06-28 19:34:55.25   Median :    6287  \n                    Mean   :2035-06-30 22:13:03.65   Mean   :   19775  \n                    3rd Qu.:2035-09-13 13:44:34.00   3rd Qu.:   12101  \n                    Max.   :2035-11-30 00:00:00.00   Max.   :28735323  \n                    NA's   :13101                    NA's   :13101     \n    source             target              date             ping_date         \n Length:271643      Length:271643      Length:271643      Min.   :2035-02-01  \n Class :character   Class :character   Class :character   1st Qu.:2035-04-17  \n Mode  :character   Mode  :character   Mode  :character   Median :2035-06-28  \n                                                          Mean   :2035-06-30  \n                                                          3rd Qu.:2035-09-13  \n                                                          Max.   :2035-11-30  \n                                                          NA's   :13101       \n\n\nNext, we ensure there are no duplicated rows\n\n\nShow the code\nlinks_df[duplicated(links_df),]\n\n\n# A tibble: 790 × 7\n   type               time   dwell source                target date  ping_date\n   &lt;chr&gt;              &lt;dttm&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;   \n 1 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 2 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 3 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 4 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 5 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 6 Event.HarborReport NA        NA wavewranglerc2d       City … 2035… NA       \n 7 Event.HarborReport NA        NA yellowfintunataker08b City … 2035… NA       \n 8 Event.HarborReport NA        NA webigailba7           City … 2035… NA       \n 9 Event.HarborReport NA        NA webigailba7           City … 2035… NA       \n10 Event.HarborReport NA        NA webigailba7           City … 2035… NA       \n# ℹ 780 more rows\n\n\nLet’s try to understand how our links data is categorized into. It seems there are three categories of data as shown below.\n\n\nShow the code\nunique_type &lt;- unique(links_df$type)\nprint(unique_type)\n\n\n[1] \"Event.TransportEvent.TransponderPing\"\n[2] \"Event.Transaction\"                   \n[3] \"Event.HarborReport\"                  \n\n\nDefine a function to count and print unique categories for a given column.\n\n\nShow the code\ncount_unique_categories &lt;- function(data, column_name) {\n  cat(\"**\", column_name, \"**\\n\", sep = \"\")\n  category_counts &lt;- table(data[[column_name]])\n  sorted_counts &lt;- sort(category_counts, decreasing = TRUE)\n  print(sorted_counts)\n}\n\n\n\n\nLet’s take a look into our nodes dataframe.\n\n\nShow the code\nglimpse(nodes_df)\n\n\nRows: 5,637\nColumns: 14\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ date                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ type_original        &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;chr&gt; \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n$ tonnage              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n\n\nAgain, it’s hard to make sense if these missing values are actually important due ot the nature of the data. We shall handle it as it goes. However, the main columns we are interested in id and type are not missing any data.\n\n\nShow the code\n# Check for columns with missing values\ncolSums(is.na(nodes_df))\n\n\n                  id                 date                 type \n                   0                  330                    0 \n       type_original             qty_tons                 name \n                   0                  330                 5627 \n                Name              company         flag_country \n                5317                 5458                 5341 \n          Activities              tonnage       length_overall \n                   0                 5359                 5354 \nfish_species_present                 kind \n                   0                 5613 \n\n\nThere does not seem to be any whole duplicate rows.\n\n\nShow the code\nnodes_df[duplicated(nodes_df),]\n\n\n# A tibble: 0 × 14\n# ℹ 14 variables: id &lt;chr&gt;, date &lt;chr&gt;, type &lt;chr&gt;, type_original &lt;chr&gt;,\n#   qty_tons &lt;dbl&gt;, name &lt;chr&gt;, Name &lt;chr&gt;, company &lt;chr&gt;, flag_country &lt;chr&gt;,\n#   Activities &lt;chr&gt;, tonnage &lt;dbl&gt;, length_overall &lt;dbl&gt;,\n#   fish_species_present &lt;list&gt;, kind &lt;chr&gt;\n\n\nIt seems we have many types of nodes even after grouping more of the Vessel types into our generic “Entity.Vessel”. It seems “Entity.Commodity.Fish”,‘Entity.Vessel’, ‘Entity.Location.Point’, ‘Entity.Location.City’, ‘Entity.Location.Region’ will be important for us.\n\n\nShow the code\nunique_type &lt;- unique(nodes_df$type)\nprint(unique_type)\n\n\n [1] \"Entity.Commodity.Fish\"          \"Entity.Location.City\"          \n [3] \"Entity.Document.DeliveryReport\" \"Entity.Vessel\"                 \n [5] \"Entity.Vessel.Other\"            \"Entity.Vessel.Ferry.Passenger\" \n [7] \"Entity.Vessel.Research\"         \"Entity.Vessel.Tour\"            \n [9] \"Entity.Location.Point\"          \"Entity.Location.Region\"        \n\n\n\n\nShow the code\ncount_unique_categories(nodes_df, 'type') \n\n\n**type**\n\nEntity.Document.DeliveryReport                  Entity.Vessel \n                          5307                            280 \n         Entity.Location.Point          Entity.Commodity.Fish \n                            12                             10 \n          Entity.Location.City         Entity.Location.Region \n                             6                              6 \n            Entity.Vessel.Tour            Entity.Vessel.Other \n                             6                              5 \n Entity.Vessel.Ferry.Passenger         Entity.Vessel.Research \n                             3                              2 \n\n\nShow the code\ncount_unique_categories(nodes_df, 'flag_country') \n\n\n**flag_country**\n\n        Oceanus     Playa Solis         Helixia         Nyxonix      Alverossia \n            177               5               4               4               3 \n       Ariuzima        Coralada        Kethanor      Lumindoria       Orvietola \n              3               3               3               3               3 \n     Utoparadia        Uzifrica        Valtalmo Anderia del Mar       Azurionix \n              3               3               3               2               2 \n      Calabrand        Faraluna       Gavanovia     Isla Solmar       Islavaria \n              2               2               2               2               2 \n      Khamseena       Kondarica        Mawalara        Merigrad      Novarctica \n              2               2               2               2               2 \n    Novarcticaa      Osterivaro     Rio Solovia       Riodelsol    Thessalandia \n              2               2               2               2               2 \n     Utoporiana         Uziland       Zawalinda      Afarivaria       Alverovia \n              2               2               2               1               1 \n   Arreciviento         Arvaros       Arvekalia        Baziuzim      Brindisola \n              1               1               1               1               1 \n    Brindivaria     Coralmarica        Helvoris         Icarnia          Imazam \n              1               1               1               1               1 \n    Islavaragon        Kethilim       Kilivaria      Kondanovia    Kondarivakia \n              1               1               1               1               1 \n     Korvelonia       Kuzalanda        Lumakari       Luminkind   Mango del Oro \n              1               1               1               1               1 \n        Marebak        Marifada      Myriadonia        Nalakond       Nalaloria \n              1               1               1               1               1 \n     Oceanterra  Puerto del Mar      Sirenareef     Solovarossa       Solterrix \n              1               1               1               1               1 \n     Syrithania       Talandria    Vesperlandia        Vientoro       Wysterion \n              1               1               1               1               1 \n    Yggdrasonia        Zambarka \n              1               1 \n\n\nShow the code\ncount_unique_categories(nodes_df, 'kind') \n\n\n**kind**\n\n               buoy                city Ecological Preserve      Fishing Ground \n                 12                   6                   3                   3 \n\n\nThere are 100 companies found in our dataset\n\ncount_unique_companies &lt;- length(unique(nodes_df$company))\ncount_unique_companies\n\n[1] 100\n\n\n\n\nThe code below snippet employs the sf package to read and manipulate GeoJSON data. It uses st_read() to import the GeoJSON file and renames the column “Name” to “id” using rename() from the dplyr package.\n\n\nShow the code\n# Read the GeoJSON file\ngeojson_file &lt;- \"data/Oceanus Information/Oceanus Geography.geojson\"\ngeo_data &lt;- st_read(geojson_file) %&gt;%\n  rename(id = Name)\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\weipengten\\ISSS608-VAA-Project\\Project\\data\\Oceanus Information\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\nUsing tmap we create a basic plot of our locations we are interested in.\n\n\nShow the code\n# Visualize the geographical data with tmap\ntmap_mode(\"plot\")\n\ntm_shape(geo_data) +\n  tm_polygons(alpha = 0.5) +\n  tm_borders(lwd = 1, alpha = 0.5) +\n  tm_layout(frame = FALSE) +\n  tmap_style(\"gray\") +\n  tm_shape(geo_data) +\n  tm_dots(col = \"purple\", size = 0.2) +\n  tm_text(text = \"id\", size = 0.6, col = \"black\") +  # Add labels to the locations\n  tm_layout(legend.position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Project/Investigations.html#task-1",
    "href": "Project/Investigations.html#task-1",
    "title": "Investigations",
    "section": "Task 1",
    "text": "Task 1"
  },
  {
    "objectID": "Project/Investigations.html#processing-fish-locations-data-and-visualizing",
    "href": "Project/Investigations.html#processing-fish-locations-data-and-visualizing",
    "title": "Investigations",
    "section": "1.1 Processing fish locations data and visualizing",
    "text": "1.1 Processing fish locations data and visualizing\n\n\nShow the code\n# Initial cleaning and splitting of fish species data\nfishing_grounds_df &lt;- fishing_grounds_df %&gt;%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = strsplit(as.character(fish_species_present), \",\\\\s*\")) %&gt;%\n  unnest(fish_species_present) %&gt;%\n  rename(fishing_location = Name)\n\n# Group by fish species and collect all unique locations into a list\nfinal_fish_locations_df &lt;- fishing_grounds_df %&gt;%\n  group_by(fish_species_present) %&gt;%\n  summarise(fishing_locations = list(unique(fishing_location)), .groups = 'drop')\n\nggplot(fishing_grounds_df, aes(x = fishing_location, y = fish_species_present, fill = kind)) +\n  geom_tile(color = \"white\") +\n  scale_fill_manual(values = c(\"Ecological Preserve\" = \"lightblue\", \"Fishing Ground\" = \"lightgreen\")) +\n  labs(title = \"Fish Distribution in Fishing Locations\",\n       x = \"Fishing Location\",\n       y = \"Fish Species\",\n       fill = \"Location Type\") +\n  theme_minimal() + theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank())+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.25, hjust=0.25))\n\n\n\n\n\nPlot above shows the locations in which various fish varieties are found. Fishing is supposed to be done only in the designated fishing grounds and not in ecological preserves\nInsights: There are some fishes like Sockfish/Pisces foetida,Helenaa/Pisces satis, Offidiaa/Piscis osseus which are found only in ecological preserves. So tracking fishing of these varieties can give leads to illegal fishing happening."
  },
  {
    "objectID": "Project/Investigations.html#processing-transactionsharbor-report-and-delivery-report-data",
    "href": "Project/Investigations.html#processing-transactionsharbor-report-and-delivery-report-data",
    "title": "Investigations",
    "section": "1.2 Processing transactions,harbor report and delivery report data",
    "text": "1.2 Processing transactions,harbor report and delivery report data\n\n\nShow the code\n# Convert date columns to Date type\ntransactions_df$date &lt;- as.Date(transactions_df$date)\nharbor_report_df$date &lt;- as.Date(harbor_report_df$date)\ndelivery_report_df$date &lt;- as.Date(delivery_report_df$date)\n\n\n\n# Performing the inner join to pick only fishing or cargo vessels\nharbor_report_df &lt;- inner_join(harbor_report_df, vessels_df, by =  c(\"source\" = \"id\")) %&gt;%\n  rename(\n    vessel_name = Name,\n    vessel_company = company,\n    vessel_id=source,\n    city=target,\n    vessel_type=type\n  ) %&gt;% \n  select(date,vessel_id,city,vessel_name,vessel_type,vessel_company,flag_country)\n\n\n\ntransponder_ping_df &lt;- inner_join(transponder_ping_df, vessels_df, by =  c(\"target\" = \"id\"))%&gt;%\n  rename(\n    location = source,\n    vessel_id = target,\n    vessel_name = Name,\n    vessel_company = company,\n    vessel_type=type\n  ) %&gt;% \n  select(time,ping_date,dwell, location,vessel_id,vessel_name,vessel_type,vessel_company,flag_country)\n\n# Group by date, vessel_id, and city, and sum up dwell time\ntransponder_ping_day_sum_df &lt;- transponder_ping_df %&gt;%\n  group_by(ping_date, vessel_id, location,vessel_name,vessel_type,vessel_company) %&gt;%\n  summarise(total_dwell_time = sum(dwell, na.rm = TRUE), .groups = 'drop') %&gt;%\n  # Add filter to exclude records where total_dwell_time is 0\n  filter(total_dwell_time != 0)\n\ntransponder_ping_city_df &lt;- transponder_ping_day_sum_df %&gt;%\n  filter(grepl(\"^City\", location))\n\ntransponder_ping_non_city_df &lt;- transponder_ping_day_sum_df %&gt;%\n  filter(!grepl(\"^City\", location))\n\ntransponder_ping_south_df &lt;- transponder_ping_day_sum_df %&gt;%\n  filter(grepl(\"^SouthSeafood Express Corp\", vessel_company))\n\n# preparing transactions\ntransactions_df&lt;-transactions_df%&gt;% rename(cargo_id = source)\n\n#pivot fish and city as columns\ncity_and_fish_df &lt;- bind_rows(city_df, fish_df)\n\ntransactions_type &lt;- transactions_df %&gt;%\n  left_join(city_and_fish_df, by = c(\"target\" = \"id\")) %&gt;%\n  select(date.x, cargo_id, target, type)\n\ntransactions_cargo &lt;- transactions_type %&gt;%\n  pivot_wider(names_from = type, values_from = target,  id_cols = c(date.x, cargo_id))%&gt;%\n  rename(\n    date=date.x,\n    fish = Entity.Commodity.Fish,\n    city = Entity.Location.City\n  )\n\ntransactions_cargo &lt;- transactions_cargo %&gt;%\n  left_join(fish_df, by = c(\"fish\" = \"id\")) %&gt;%\n  select(date.x, cargo_id, fish, city,fish_name)%&gt;%\nrename(date_of_arrival=date.x,\n       city_of_arrival=city,\n       fish_in_cargo=fish\n       )\n\ntransactions_cargo &lt;- transactions_cargo %&gt;%\n  left_join(delivery_report_df, by = c(\"cargo_id\"=\"cargo_id\",\"date_of_arrival\" = \"date\")) %&gt;%\n  select(date_of_arrival,cargo_id, fish_in_cargo, city_of_arrival,fish_name,qty_tons)"
  },
  {
    "objectID": "Project/Investigations.html#exploring-outlier-data",
    "href": "Project/Investigations.html#exploring-outlier-data",
    "title": "Investigations",
    "section": "1.3 Exploring outlier data",
    "text": "1.3 Exploring outlier data\n\n\nShow the code\niqr_qty &lt;- IQR(transactions_cargo$qty_tons)\nupper_bound &lt;- quantile(transactions_cargo$qty_tons, 0.75) + 1.5 * iqr_qty\noutliers &lt;- transactions_cargo[transactions_cargo$qty_tons &gt; upper_bound, ]\n# Create a histogram\nhist(transactions_cargo$qty_tons)\n\n# Add outliers as points\npoints(transactions_cargo$qty_tons[transactions_cargo$qty_tons &gt; upper_bound], \n       rep(0, sum(transactions_cargo$qty_tons &gt; upper_bound)), \n       col = \"red\", pch = 16)\n\n\n\n\n\nInsight : Anomaly qty_tons are mostly greater than 70 tons"
  },
  {
    "objectID": "Project/Investigations.html#plotting-fish-arrivals-over-time",
    "href": "Project/Investigations.html#plotting-fish-arrivals-over-time",
    "title": "Investigations",
    "section": "1.4 Plotting fish arrivals over time",
    "text": "1.4 Plotting fish arrivals over time\n\n\nShow the code\nmonthly_data &lt;- transactions_cargo %&gt;%\n  mutate(month = format(date_of_arrival, \"%Y-%m\"))\n\n# Convert month to Date type for proper ordering in ggplot2\nmonthly_data$month &lt;- as.Date(paste0(monthly_data$month, \"-01\"))\n\n# Group by month and fish_name, and summarize total quantity in tons\nmonthly_data &lt;- monthly_data %&gt;%\n  group_by(month, fish_name) %&gt;%\n  summarize(total_qty = sum(qty_tons)) %&gt;%\n  ungroup()\n\n# Plot the data\np &lt;- ggplot(monthly_data, aes(x = month, y = total_qty, color = fish_name, group = fish_name)) +\n  geom_line() +\n  labs(title = \"Monthly Fish Transactions\", x = \"Month\", y = \"Quantity in Tons\")\n\nggplotly(p)\n\n\n\n\n\n\nInsights:\n\nHuge increase in Cod arrivals starting from July. This can be investigated for illegal fishing exceeding allowed limits.\nThere are Salmon cargoes arriving,but cant attribute salmon to fishing grounds or ecological preserves. So it might be unregulated fishing from locations where fishing is not supposed to be done.\nProtected species ( Sockfish/Pisces foetida,Helenaa/Pisces satis, Offidiaa/Piscis osseus ) are arriving in cargo and need to be explored"
  },
  {
    "objectID": "Project/Investigations.html#plotting-protected-fish-quantities-arriving-at-each-city-over-time",
    "href": "Project/Investigations.html#plotting-protected-fish-quantities-arriving-at-each-city-over-time",
    "title": "Investigations",
    "section": "1.5 Plotting protected fish quantities arriving at each city over time",
    "text": "1.5 Plotting protected fish quantities arriving at each city over time\n\n\nShow the code\ncity_time_analysis &lt;- transactions_cargo %&gt;%\n  mutate(month_of_arrival = format(date_of_arrival, \"%Y-%m\"))\n\n# Convert month to Date type for proper ordering in ggplot2\ncity_time_analysis$month_of_arrival &lt;- as.Date(paste0(city_time_analysis$month_of_arrival, \"-01\"))\n\n# Group by month and fish_name, and summarize total quantity in tons\ncity_time_analysis &lt;- city_time_analysis %&gt;%\n  group_by(month_of_arrival,city_of_arrival,fish_name) %&gt;%\n  summarize(total_qty = sum(qty_tons)) %&gt;%\n  ungroup()\n\n# Example endangered fish list\nendangered_fish &lt;- c(\" Helenaa/Pisces satis\", \"Offidiaa/Piscis osseus\",\"Sockfish/Pisces foetida\")\n\n# Generate a color palette, highlighting endangered species\nfish_colors &lt;- ifelse(city_time_analysis$fish_name %in% endangered_fish, \"red\", \"grey\")  # This creates a vector of 'red' or 'grey'\nunique_fish &lt;- unique(city_time_analysis$fish_name)\ncolors &lt;- setNames(ifelse(unique_fish %in% endangered_fish, \"red\", \"grey\"), unique_fish)\n\n# Add a custom color scale to the plot\np &lt;- ggplot(city_time_analysis, aes(x = month_of_arrival, y = total_qty, fill = fish_name)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_manual(values = colors) +\n  facet_wrap(~ city_of_arrival, scales = \"free_y\") +\n  labs(title = \"Fish Arrivals by City Over Time\", subtitle = \"Red highlights endangered species\",\n       x = \"Month of Arrival\", y = \"Total Quantity in Tons\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.title = element_text(face = \"bold\"))\n\n# Convert to an interactive plotly plot\ninteractive_plot &lt;- ggplotly(p)\n\ninteractive_plot &lt;- interactive_plot %&gt;%\n  layout(\n    hoverlabel = list(bgcolor = \"white\"),\n    hoverinfo = \"text\",\n    tooltip = c(\"month_of_arrival\", \"qty_tons\", \"fish_name\")\n  )\ninteractive_plot"
  },
  {
    "objectID": "Project/Investigations.html#logic-for-inferring-mapping-between-cargo-and-vessel",
    "href": "Project/Investigations.html#logic-for-inferring-mapping-between-cargo-and-vessel",
    "title": "Investigations",
    "section": "1.6 Logic for inferring mapping between cargo and vessel",
    "text": "1.6 Logic for inferring mapping between cargo and vessel\nThis code is designed to match fish cargo transactions with vessel activities using harbor reports and transponder pings. It aims to identify potential vessels involved in direct deliveries or transshipment activities for specific fish cargoes. The goal is to provide a comprehensive mapping of cargoes to vessels, especially focusing on cases with multiple possible matches.\n\n\nShow the code\n#matching based on harbor report and transponder ping\nmatching_cargo_to_vessel_harbor &lt;- transactions_cargo %&gt;%\n  inner_join(harbor_report_df, by = c(\"city_of_arrival\" = \"city\")) %&gt;%\n  filter(date_of_arrival == date | date_of_arrival - days(1) == date) %&gt;%\n  select(date_of_arrival, date,cargo_id,fish_in_cargo,city_of_arrival,vessel_id,vessel_company,vessel_type,qty_tons)\n\nmatching_cargo_to_vessel_transponder &lt;- transactions_cargo %&gt;%\n  inner_join(transponder_ping_city_df, by = c(\"city_of_arrival\" = \"location\")) %&gt;%\n  filter(date_of_arrival == ping_date | date_of_arrival - days(1) == ping_date) %&gt;%\n  select(date_of_arrival, ping_date,city_of_arrival,cargo_id,fish_in_cargo,vessel_id,vessel_name,vessel_company,vessel_type,total_dwell_time,qty_tons)\n\ncombined_matches &lt;- bind_rows(\n  matching_cargo_to_vessel_harbor %&gt;% mutate(source = \"Harbor\"),\n  matching_cargo_to_vessel_transponder %&gt;% mutate(source = \"Transponder\")\n) %&gt;%\n  group_by(cargo_id,vessel_id,source) %&gt;%\n    slice(1) %&gt;%\n  ungroup()  %&gt;%\n  # Filter to prioritize harbor data\nfilter(if(any(source == \"Harbor\")) source == \"Harbor\" else source ==\"Transponder\")%&gt;%  rename(\n    date_matched_in_harbor_report = date,\n    date_matched_in_transponder_ping = ping_date\n  )\n  \n\nlibrary(purrr)\n\ndaily_vessel_locations_list &lt;- transponder_ping_day_sum_df %&gt;%\n  group_by(ping_date, vessel_id, vessel_company) %&gt;%\n  summarise(ping_locations = list(unique(location)), .groups = 'drop')\n\n# Function to find potential transshipment vessels for a single transaction\nfind_potential_vessels_single &lt;- function(date_of_arrival, cargo_id, city_of_arrival, fish_in_cargo) {\n  date_to &lt;- date_of_arrival\n  date_from &lt;- date_to - 5\n  target_location &lt;- city_of_arrival\n\n  \n  # Get the fishing locations for the fish in the cargo\n  fish_locations &lt;- final_fish_locations_df %&gt;%\n    filter(fish_species_present == fish_in_cargo) %&gt;%\n    pull(fishing_locations) %&gt;%\n    unlist()\n  \n  # Direct delivery check\n  direct_vessels &lt;- daily_vessel_locations_list %&gt;%\n    filter(ping_date &gt;= date_from & ping_date &lt;= date_to) %&gt;%\n    filter(map_lgl(ping_locations, ~ any(.x %in% fish_locations))) %&gt;%\n    filter(map_lgl(ping_locations, ~ any(.x == target_location))) %&gt;%\n   # filter(vessel_company == cargo_company) %&gt;%\n    distinct(vessel_id) %&gt;%\n    pull(vessel_id)\n  \n  if (length(direct_vessels) &gt; 0) {\n    return(data.frame(\n      cargo_id = cargo_id,\n      vessel_id = direct_vessels\n    ))\n  }\n  \n  # Transshipment check\n  vessels_visiting_fish_location &lt;- daily_vessel_locations_list %&gt;%\n    filter(ping_date &gt;= date_from & ping_date &lt;= date_to) %&gt;%\n    filter(map_lgl(ping_locations, ~ any(.x %in% fish_locations))) %&gt;%\n   # filter(vessel_company == cargo_company) %&gt;%\n    distinct(vessel_id) %&gt;%\n    pull(vessel_id)\n  \n  vessels_visiting_target_location &lt;- daily_vessel_locations_list %&gt;%\n    filter(ping_date &gt;= date_from & ping_date &lt;= date_to) %&gt;%\n    filter(map_lgl(ping_locations, ~ any(.x == target_location))) %&gt;%\n   # filter(vessel_company == cargo_company) %&gt;%\n    distinct(vessel_id) %&gt;%\n    pull(vessel_id)\n  \n  combined_vessels &lt;- unique(c(vessels_visiting_fish_location, vessels_visiting_target_location))\n  \n  confirmed_vessels_on_date &lt;- harbor_report_df %&gt;%\n    filter(date == date_to & city == target_location & vessel_id %in% combined_vessels) %&gt;%\n    distinct(vessel_id) %&gt;%\n    pull(vessel_id)\n  \n  if (length(confirmed_vessels_on_date) == 0) {\n    return(data.frame(\n      cargo_id = cargo_id,\n      vessel_id = NA\n    ))\n  } else {\n    return(data.frame(\n      cargo_id = cargo_id,\n      vessel_id = confirmed_vessels_on_date\n    ))\n  }\n}\n\n# Identify cargos with more than 3 mapping in combined_matches\ncargos_with_multiple_mappings &lt;- combined_matches %&gt;%\n  group_by(cargo_id) %&gt;%\n  summarise(count = n()) %&gt;%\n  filter(count &gt; 3) %&gt;%\n  pull(cargo_id)\n\n# Filter transactions_cargo to include only those cargos\nrequired_columns &lt;- transactions_cargo %&gt;%\n  filter(cargo_id %in% cargos_with_multiple_mappings) %&gt;%\n  select(date_of_arrival, cargo_id, city_of_arrival, fish_in_cargo)\n\n \n\n# Apply the function to all transactions using pmap_dfr\nresults &lt;- pmap_dfr(required_columns, function(...) {\n  find_potential_vessels_single(...)\n})\n\n\n# Identify cargos with &lt;=3 mapping in combined_matches\ncargos_with_less_than_3_mapping &lt;- combined_matches %&gt;%\n  group_by(cargo_id) %&gt;%\n  summarise(count = n()) %&gt;%\n  filter(count &lt;=3) %&gt;%\n  pull(cargo_id)\n\n# Select from combined_matches for cargos with &lt;=3 mapping mapping\ncombined_matches_3 &lt;- combined_matches %&gt;%\n  filter(cargo_id %in% cargos_with_less_than_3_mapping)\n\n# Select from results where vessel_id is not NA\nresults_valid &lt;- results %&gt;%\n  filter(!is.na(vessel_id))\n\n# Fallback to combined_matches for cargos not matched in results\nfallback_cargos &lt;- results %&gt;%\n  filter(is.na(vessel_id)) %&gt;%\n  pull(cargo_id)\n\ncombined_matches_fallback &lt;- combined_matches %&gt;%\n  filter(cargo_id %in% fallback_cargos)\n\n# Combine the selected and fallback results\ncombined_results_final &lt;- bind_rows(combined_matches_3, results_valid, combined_matches_fallback)"
  },
  {
    "objectID": "Project/Investigations.html#sankey-diagram-for-showing-the-flow-of-fish-through-the-port-cities",
    "href": "Project/Investigations.html#sankey-diagram-for-showing-the-flow-of-fish-through-the-port-cities",
    "title": "Investigations",
    "section": "1.7 Sankey diagram for showing the flow of fish through the port cities",
    "text": "1.7 Sankey diagram for showing the flow of fish through the port cities\nThis code aims to create a Sankey diagram that visualizes the flow of fish quantities from vessel companies to their respective cities of arrival and the types of fish in their cargo. The goal is to illustrate the distribution and connections between these entities, focusing on the top 10 vessel companies by quantity.\n\n\nShow the code\n# Aggregate data for Sankey diagram\nsankey_data &lt;- combined_results_final %&gt;%\n  group_by(vessel_company, city_of_arrival, fish_in_cargo) %&gt;%\n  summarize(total_qty_tons = sum(qty_tons), .groups = 'drop')\n\n# Filter to top 10 vessel companies by quantity\ntop_companies &lt;- sankey_data %&gt;%\n  group_by(vessel_company) %&gt;%\n  summarize(total_qty_tons = sum(total_qty_tons), .groups = 'drop') %&gt;%\n  top_n(10, total_qty_tons) %&gt;%\n  pull(vessel_company)\n\nsankey_data &lt;- sankey_data %&gt;%\n  filter(vessel_company %in% top_companies)\n\n# Create node labels\nnodes &lt;- unique(c(sankey_data$vessel_company, sankey_data$city_of_arrival, sankey_data$fish_in_cargo))\nnode_indices &lt;- setNames(seq_along(nodes) - 1, nodes)\n\n# Create source and target indices\nsankey_data &lt;- sankey_data %&gt;%\n  mutate(source = node_indices[vessel_company],\n         target_city = node_indices[city_of_arrival],\n         target_fish = node_indices[fish_in_cargo])\n\n# Create Sankey diagram\nfig &lt;- plot_ly(\n  type = \"sankey\",\n  orientation = \"h\",\n  node = list(\n    label = nodes,\n    pad = 15,\n    thickness = 20,\n    line = list(color = \"black\", width = 0.5)\n  ),\n  link = list(\n    source = c(sankey_data$source, sankey_data$target_city),\n    target = c(sankey_data$target_city, sankey_data$target_fish),\n    value = c(sankey_data$total_qty_tons, sankey_data$total_qty_tons)\n  )\n)\n\nfig %&gt;%\n  layout(\n    title = \"Sankey Diagram of Top 10 Vessel Companies by Fish Quantity\",\n    font = list(size = 10)\n  )"
  },
  {
    "objectID": "Project/Investigations.html#treemap",
    "href": "Project/Investigations.html#treemap",
    "title": "Investigations",
    "section": "1.8 Treemap",
    "text": "1.8 Treemap\nThis code aims to create a treemap visualization that displays the quantity of fish transported by different vessel companies to various cities, based on the mapping we created earlier in 1.6. The goal is to provide a clear and intuitive representation of the distribution and magnitude of fish quantities across multiple dimensions (cities and companies).\n\n\nShow the code\nlibrary(treemap)\n\nall_cities &lt;- unique(combined_results_final$city_of_arrival)\nall_vessel_companies &lt;- unique(combined_results_final$vessel_company)\n\n# Create a data frame with all combinations of cities and vessel companies\ncomplete_data &lt;- expand.grid(\n  city_of_arrival = all_cities,\n  vessel_company = all_vessel_companies,\n  stringsAsFactors = FALSE\n)\n\n# Merge the complete_data with combined_matches to ensure all cities and vessel companies are included\nmerged_data &lt;- merge(complete_data, combined_results_final, by = c(\"city_of_arrival\", \"vessel_company\"), all.x = TRUE)\n\n# Replace NA values with 0 for qty_tons\nmerged_data$qty_tons[is.na(merged_data$qty_tons)] &lt;- 0\n\n# Aggregate data for treemap\ntreemap_data &lt;- merged_data %&gt;%\n  group_by(city_of_arrival, vessel_company) %&gt;%\n  summarize(total_qty_tons = sum(qty_tons), .groups = 'drop')\n\n# Normalize the values for better visualization\ntreemap_data$total_qty_tons &lt;- log1p(treemap_data$total_qty_tons)\n\n# Create the treemap\ntreemap(treemap_data,\n              index = c(\"city_of_arrival\", \"vessel_company\"),\n              vSize = \"total_qty_tons\",\n              vColor = \"total_qty_tons\",\n              type = \"value\",\n              fontsize.labels = c(20, 12), # Larger font size for inner labels\n              align.labels = list(c(\"center\", \"center\"), c(\"center\", \"center\")), # Center align labels\n              #inflate.labels = TRUE, # Inflate labels to fit the tiles\n              title = \"Treemap of Fish Quantity by Vessel Company for Each City\",\n              title.legend = \"Total Quantity (Log Scale)\")"
  },
  {
    "objectID": "Project/Investigations.html#plotting-fish-quantities-arriving-at-each-city-over-time",
    "href": "Project/Investigations.html#plotting-fish-quantities-arriving-at-each-city-over-time",
    "title": "Investigations",
    "section": "1.9 Plotting fish quantities arriving at each city over time",
    "text": "1.9 Plotting fish quantities arriving at each city over time\n\n\nShow the code\n# Aggregate quantity by city, fish type, and month of arrival (assuming you have a date_of_arrival column)\n\ncity_time_analysis &lt;- transactions_cargo %&gt;%\n  mutate(month_of_arrival = lubridate::floor_date(date_of_arrival, \"month\")) %&gt;%\n  group_by(city_of_arrival, fish_name, month_of_arrival) %&gt;%\n  summarize(qty_tons = sum(qty_tons), .groups = 'drop')\n\n\n# Plot with ggplot2\np &lt;- ggplot(city_time_analysis, aes(x = month_of_arrival, y = qty_tons, fill = fish_name)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  facet_wrap(~ city_of_arrival, scales = \"free_y\") +\n  labs(title = \"Fish Arrivals by City Over Time\", x = \"Month of Arrival\", y = \"Total Quantity in Tons\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convert to an interactive plotly plot\nggplotly(p)\n\n\n\n\n\n\nInsights:\n\nCod arrival increased significantly in Paackland,South Paackland and Lomark from July\nSignificant consistent increase in Wrasse arrivals in Himark\nSockfish arrived significantly in Hacklee and Himark in November\nOffidiaa arrived significantly in Paackland in November"
  },
  {
    "objectID": "Project/Investigations.html#task-2",
    "href": "Project/Investigations.html#task-2",
    "title": "Investigations",
    "section": "Task 2",
    "text": "Task 2\nExploring activities of SouthSeafood Express Corp\n\n2.1 Plotting Monthly Dwell time of vessels belonging to SouthSeafood Express Corp\n\n\nShow the code\n# Aggregate dwell time by month, city, and vessel_id\ndwell_time_by_month_city_vessel &lt;- transponder_ping_df %&gt;%\n  filter(vessel_company == \"SouthSeafood Express Corp\") %&gt;%\n  mutate(month = format(ping_date, \"%Y-%m\")) %&gt;%\n  group_by(month, location, vessel_id) %&gt;%\n  summarise(monthly_dwell_time = sum(dwell), .groups = 'drop')\n\n# Plotting with faceting by vessel_id\np2 &lt;- ggplot(dwell_time_by_month_city_vessel, aes(y = month, x = monthly_dwell_time, fill = location)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~vessel_id, scales = \"free_y\") +  # Free scales can be set if necessary\n  labs(title = \"Monthly Dwell Time by City for Company A, by Vessel\",\n       y = \"Month\",\n       x = \"Dwell Time\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",axis.text.x = element_text(angle = 90, hjust = 1),\n        strip.text.x = element_text(angle = 0, hjust = 0.5, size = 8))  # Adjust strip text for better readability\n\nggplotly(p2)\n\n\n\n\n\n\n\nInsights:\n\nSouthSeafood Express Corp seems to have been caught in the month of May as transponder pings stops at May\nVessel snappersnatcher7be seems to have spent considerable time in ecological preserve ‘ghoti preserve’ in april and in wrasse beds in april. The common fish present in both locations in Wrasse.\n\n\n\n2.2 Heatmap of dwell time\n\n\nShow the code\nggplot(transponder_ping_south_df, aes(x = ping_date, y = location, fill = total_dwell_time)) +\n      geom_tile(color = \"white\") +  # Adds borders to each tile\n      scale_fill_gradient(low = \"lightblue\", high = \"darkblue\", name = \"Dwell Time\") +  # Color gradient\n      facet_wrap(~ vessel_id, ncol = 1, scales = \"free_y\")+\n      labs(title = \"Heatmap of Vessel Location Dwell Times\", x = \"Date\", y = \"Location\") +\n      theme_minimal() +\n      theme(\n        axis.text.x = element_text(angle = 90, hjust = 1),  # Rotate date labels for clarity\n        axis.title = element_text(size = 12, face = \"bold\")\n      )\n\n\n\n\n\nInsight:\nVessels seem to be spending time in exit east as well Himark and Lomark.\n\n\n2.3. Deep dive into SouthSeafood Express Corp\n\n\nShow the code\nlibrary(ggraph)\n\n# Filter the dataframe for a specific company \ntransponder_ping_filtered_df &lt;- transponder_ping_day_sum_df %&gt;%\n  filter(vessel_company == \"SouthSeafood Express Corp\")\n\n# Create edge list for the graph\n# Here, 'from' represents the vessel, and 'to' represents the city (location)\nedges_df &lt;- data.frame(\n  from = transponder_ping_filtered_df$vessel_id,\n  to = transponder_ping_filtered_df$location,\n  weight = transponder_ping_filtered_df$total_dwell_time # Use dwell time as weight for edge thickness\n)\n\n# Create the graph object\ngraph &lt;- graph_from_data_frame(edges_df, directed = FALSE)\n\n# Define node types\nV(graph)$type &lt;- ifelse(V(graph)$name %in% transponder_ping_filtered_df$vessel_id, \"vessel\", \"location\")\n\n# Visualize the network with ggraph\nggraph(graph, layout = 'fr') +  \n  geom_edge_link(aes(edge_width = weight), edge_colour = \"grey\") + # Edge thickness based on dwell time\n  geom_node_point(aes(color = type), size = 5) + \n  geom_node_text(aes(label = name), repel = TRUE, size = 3, color = \"black\") +  \n  scale_color_manual(values = c(\"vessel\" = \"orange\", \"location\" = \"plum\")) + \n  theme_void() +  \n  labs(title = \"Network Visualization of Vessel Movements for SouthSeafood Express Corp\")\n\n\n\n\n\nCentral and High-Activity Locations:\n\nCity of Himark and City of Lomark: These locations have multiple connections and thicker edges, indicating they are key hubs with significant vessel activity or prolonged stays.\nWrasse Beds and Ghoti Preserve: Similarly, these locations are prominent in terms of connections and might represent areas where they are performing illegal fishing\nLocations with Thicker Edges: Locations like “Exit East” connected by thicker edges suggest that these are areas where vessels tend to stay longer, possibly for transshipment activities.\nPaths and Connections: The arrangement of nodes and connections shows how vessels move from one location to another, which locations are frequently connected, and how dense the network is in specific regions.\nThe path plotting show how vessels move from one location to another and which locations are frequently connected\nsnappersnatcher seems to use Exit east for transshipment activities\nroachrobberdb6 seems to use Nav A and Nav E for transshipment activities\n\n\n\n2.3. Deep dive into “snappersnatcher7b”\n\n1. Processing Transaction Data2. Suspicious Transactions3. Suspicious FindingsGeographical Plot for Suspicious and Legitimate Transportation Activities\n\n\nRetrieve and process transaction data to identify suspicious transactions.\nLet’s retrieve the Transaction data by applying the filter type == \"Event.Transaction\" for our links data\nWe then perform a self-join on the transaction dataset on source column to get the respective city and fish column for each cargo delivery, filtering for only the two cities we observed earlier ‘City of Paackland’, ‘City of Lomark’ which snappersnatcher7b frequented.\n\n\nShow the code\n# Retrieve and process transaction data\ntransactions &lt;- links_df %&gt;%\n  filter(type == \"Event.Transaction\") %&gt;%\n  filter(!is.na(source) & !is.na(target)) %&gt;%\n  group_by(source) %&gt;%\n  mutate(row_number = row_number(),\n         date = as.Date(as.character(date), format = \"%Y-%m-%d\")) %&gt;%\n  pivot_wider(names_from = row_number, values_from = target) %&gt;%\n  rename(city = `2`, fish = `1`) %&gt;%\n  rename(transaction_date = date) %&gt;%\n  select(source, fish, city, type, transaction_date) %&gt;%\n  inner_join(fish_df, by = c(\"fish\" = \"id\"))\n\n\nNo duplicated transaction records were found after the self-join\n\n\nShow the code\nduplicated_transactions &lt;- transactions[duplicated(transactions$source), ]\nduplicated_transactions\n\n\n# A tibble: 0 × 18\n# Groups:   source [0]\n# ℹ 18 variables: source &lt;chr&gt;, fish &lt;chr&gt;, city &lt;chr&gt;, type.x &lt;chr&gt;,\n#   transaction_date &lt;date&gt;, date &lt;chr&gt;, type.y &lt;chr&gt;, type_original &lt;chr&gt;,\n#   qty_tons &lt;dbl&gt;, fish_name &lt;chr&gt;, Name &lt;chr&gt;, company &lt;chr&gt;,\n#   flag_country &lt;chr&gt;, Activities &lt;chr&gt;, tonnage &lt;dbl&gt;, length_overall &lt;dbl&gt;,\n#   fish_species_present &lt;list&gt;, kind &lt;chr&gt;\n\n\n\n\nMerge the transactions with HarborReport data to identify relevant suspicious transactions.\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlysnappersnatcher7b’s records then merge with transactions dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with snappersnatcher7be’s harbor reporting to guess its cargo\n\n\nShow the code\n# Retrieve HarborReport data for \"snappersnatcher7be\"\nharboureport_culprit&lt;- links_df %&gt;%\n  mutate(date = as.Date(as.character(date), format = \"%Y-%m-%d\"))%&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"snappersnatcher7be\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\n# Merge with transactions and apply filter condition\nmerged_data &lt;- merge(transactions, harboureport_culprit, by = \"city\", all.x = TRUE)\n\n\nfiltered_transactions &lt;- merged_data %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(fish_name , fish, city,harboreporting_date,transaction_date, vessel)\n\n\nWe generate a timeline plot illustrating suspicious transactions and harbor reports associated with the vessel “snappersnatcher7be,” showcasing the relationship between transaction dates, cargo types, vessels, and cities involved.\nIt’s likely to have made transactions of cargo “Wrasse/Labridae n.refert” within thisdate range shown.\n\n\nShow the code\n# Create the timeline plot\nggplot(filtered_transactions)  +\n  geom_segment(aes(x = transaction_date, xend = harboreporting_date, y = fish_name, yend = fish_name, color = vessel), size = 1.5) +\n  geom_point(aes(x = transaction_date, y = fish_name, color = vessel, shape = city), size = 3) +\n  labs(title = \"Suspicious Transactions and Harbor Reports for snappersnatcher7be\", x = \"Date\", y = \"Cargo Type\") +\n  theme_minimal() +\n  scale_color_discrete(name = \"Vessel\") +\n  scale_shape_discrete(name = \"City\") +  # Add legend for city\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nFrom our observations, “snappersnatcher7be” is likely carrying the following cargo:\n\n“Cod/Gadus n.specificatae” around 20th March and\n“Wrasse/Labridae n.refert” around 8th May\n\nAdditionally, we found its transportation activities suspicious due to its frequent visits to “Ghoti Preserve”:\n\n\"Nav 1\": 17 occurences\n\"Nav 2\": 7 occurences\n\nFor legitimate occurrences related to “Wrasse/Labridae n.refert”, there’s fewer:\n\n\"Nav C\": 10 occurences\n\"Wrasse Beds\": 3 occurences\n\n\n\nShow the code\n# Retrieve TransponderPing data for \"snappersnatcher7be\"\ntransponder_culprit &lt;- links_df %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"snappersnatcher7be\",\n         time &lt;= \"2035-05-09\",\n         time &gt;= \"2035-04-09\")\n\n\n#### Bar Plot for Suspicious and Legitimate Transportation Activities\n\n# Data for transportation activities\nlocation_counts &lt;- transponder_culprit %&gt;%\n  filter(!source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Type = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",\n    TRUE ~ \"Legitimate\"\n  ))\n\n# Reorder Location factor levels so \"Suspicious\" locations appear at the top\nlocation_counts &lt;- location_counts %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Type, decreasing = TRUE)])))\n\n# Bar plot for transportation activities\nggplot(location_counts, aes(x = Occurrences, y = Location, fill = Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Transportation Activities of snappersnatcher7be\", x = \"Number of Occurrences\", y = \"Location\") +\n  scale_fill_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nBelow, is the geographical representation of what we found to be legitmate and suspicious locations for the vessel.\n\n\nShow the code\nlocation_counts &lt;- transponder_culprit %&gt;%\n  filter(source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"Nav 1\", \"Nav 2\", \"Ghoti Preserve\", \"Exit East\", \"Nav C\", \"Wrasse Beds\", \"Don Limpet Preserve\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Marked = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",   TRUE ~ \"Legitimate\"\n  )) %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Marked, decreasing = TRUE)])))  # Reorder Location factor levels\n\n# Merge location counts with geo data\ngeo_data_0 &lt;- left_join(geo_data, location_counts, by = c(\"id\" = \"Location\"))\n\n# Extract coordinates from geometry data\ncoords_0 &lt;- st_coordinates(st_centroid(geo_data_0))\n\n# Add coordinates to the geo_data\ngeo_data_0$Longitude &lt;- coords_0[,1]\ngeo_data_0$Latitude &lt;- coords_0[,2]\n\n\n# Filter for specific IDs to label\nlabel_ids_0 &lt;- c('Cod Table', 'Exit East', 'City of Paackland', 'City of Lomark', 'Nav 1', 'Nav 2', 'Ghoti Preserve', 'Exit East', 'Nav C', 'Wrasse Beds', 'Don Limpet Preserve')\ngeo_data_labels_0 &lt;- geo_data_0 %&gt;%\n  filter(id %in% label_ids_0)\n\n# Set plot size (for RStudio or other environments that support resizing)\noptions(repr.plot.width = 10, repr.plot.height = 8)\n\n# Geographical plot with labels\nggplot() +\n  geom_sf(data = geo_data_labels_0, aes(geometry = geometry, color = Marked)) +\n  geom_text(data = geo_data_labels_0 , aes(x = Longitude, y = Latitude, label = id), size = 2, color = \"black\", fontface = \"bold\") +\n  scale_color_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  labs(title = \"Geographical Plot of snappersnatcher7be Activities\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 16),  # Enlarge title\n        legend.title = element_text(size = 12),  # Enlarge legend title\n        legend.text = element_text(size = 10),  # Enlarge legend text\n        axis.text = element_text(size = 10),  # Enlarge axis text\n        axis.title = element_text(size = 12))  # Enlarge axis title\n\n\n\n\n\n\n\n\n\n\n2.4. Deep Investigations into “roachrobberdb6”\n\n1. Suspicious Transactions2. No Suspicious Findings3. Geographical Visualisation\n\n\nMerge the transactions with HarborReport data to identify relevant suspicious transactions.\nNext, we proceed with the HarborReport data by applying filter type == Event.HarborReport to our links dataset and retrieve onlyroachrobberdb6’s records then merge with transactions dataset to filter out relevant suspicious transactions given the fact that the harbor reports are likely to be a few days after the transaction.\nNote that, this is a rough merge on city, hence we are just narrowing down and end up with likely pairs of transactions with roachrobberdb6’s harbor reporting to guess its cargo\n\n\nShow the code\n# Retrieve HarborReport data for \"roachrobberdb6\"\nharboureport_culprit1&lt;- links_df %&gt;%\n  mutate(date = as.Date(as.character(date), format = \"%Y-%m-%d\"))%&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  filter(source ==\"roachrobberdb6\") %&gt;%\n  rename(vessel = source) %&gt;%\n  rename(city = target) %&gt;%\n  rename(harboreporting_date = date) %&gt;%\n  select(city, vessel, type, harboreporting_date)\n\n\n# Merge with transactions and apply filter condition\nmerged_data1 &lt;- merge(transactions, harboureport_culprit1, by = \"city\", all.x = TRUE)\n\n\nfiltered_transactions1 &lt;- merged_data1 %&gt;%\n  filter(harboreporting_date &gt;= transaction_date + 1 &  # Change the number based on your lag\n         harboreporting_date &lt;= transaction_date + 3) %&gt;%\n  select(fish_name, fish, city,harboreporting_date,transaction_date, vessel)\n\n\nWe generate a timeline plot illustrating suspicious transactions and harbor reports associated with the vessel “roachrobberdb6,” showcasing the relationship between transaction dates, cargo types, vessels, and cities involved.\n\n\nShow the code\n# Create the timeline plot\nggplot(filtered_transactions1) +\n  geom_segment(aes(x = transaction_date, xend = harboreporting_date, y = fish_name, yend = fish_name, color = vessel), size = 1.5) +\n  geom_point(aes(x = transaction_date, y = fish_name, color = vessel, shape = city), size = 3) +\n  labs(title = \"Suspicious Transactions and Harbor Reports for roachrobberdb6\", x = \"Date\", y = \"Cargo Type\") +\n  theme_minimal() +\n  scale_color_discrete(name = \"Vessel\") +\n  scale_shape_discrete(name = \"City\") +  # Add legend for city\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nFrom our observations previously, “roachrobberdb6” is likely carrying the following cargo:\n\n“Wrasse/Labridae n.refert” around February and April\n“Harland/Piscis sapidum” in April\n\nWe found very few of its fishing activities to be suspicious between the period however for the date range. It is likely not to be suspicious.\n\n\"Nav 1\": 2 occurences\n\"Nav C\": 38 occurences\n\"Wrasse Beds\": 42 occurences\n\n\n\nShow the code\n# Retrieve TransponderPing data for \"roachrobberdb6\"\ntransponder_culprit1 &lt;- links_df %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\",\n         target == \"roachrobberdb6\",\n         time &lt;= \"2035-04-05\")\n  \n\n#### Bar Plot for Suspicious and Legitimate Transportation Activities\n\n# Data for transportation activities\nlocation_counts1 &lt;- transponder_culprit1 %&gt;%\n  filter(!source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"City of Himark\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Type = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",\n    TRUE ~ \"Legitimate\"\n  ))\n\n# Reorder Location factor levels so \"Suspicious\" locations appear at the top\nlocation_counts1 &lt;- location_counts1 %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Type, decreasing = TRUE)])))\n\n# Bar plot for transportation activities\nggplot(location_counts1, aes(x = Occurrences, y = Location, fill = Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Transportation Activities of roachrobberdb6\", x = \"Number of Occurrences\", y = \"Location\") +\n  scale_fill_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0, face = \"bold\"),  # Align the title to the left\n    plot.title.position = \"plot\"                          # Ensure title alignment is based on the entire plot area\n  )\n\n\n\n\n\n\n\nBelow, is the geographical representation of what we found to be legitmate and suspicious locations for the vessel.\n\n\nShow the code\n# Create location_counts1 with the Marked column\nlocation_counts1 &lt;- transponder_culprit1 %&gt;%\n  filter(source %in% c('Cod Table', 'Exit East',\"City of Paackland\", \"City of Lomark\",\"Nav 1\", \"Nav 2\", \"Ghoti Preserve\", \"Exit East\", \"Nav C\", \"Wrasse Beds\", \"Don Limpet Preserve\",\"Nemo Preserve\",\"Tuna Shelf\")) %&gt;% \n  group_by(source) %&gt;%\n  summarise(Occurrences = n()) %&gt;%\n  ungroup() %&gt;%\n  rename(Location = source) %&gt;%\n  mutate(Marked = case_when(\n    Location %in% c(\"Nav 1\", \"Nav 2\") ~ \"Suspicious\",   \n    TRUE ~ \"Legitimate\"\n  )) %&gt;%\n  mutate(Location = factor(Location, levels = unique(Location[order(Marked, decreasing = TRUE)])))  # Reorder Location factor levels\n\n# Merge location counts with geo_data to include the Marked column\ngeo_data_1 &lt;- left_join(geo_data, location_counts1, by = c(\"id\" = \"Location\"))\n\n# Extract coordinates from geometry data\ncoords_1 &lt;- st_coordinates(st_centroid(geo_data_1))\n# Warning: st_centroid assumes attributes are constant over geometries\n\n# Add coordinates to the geo_data\ngeo_data_1$Longitude &lt;- coords_1[,1]\ngeo_data_1$Latitude &lt;- coords_1[,2]\n\n# Filter for specific IDs to label\nlabel_ids &lt;- c('Cod Table', 'Exit East', 'City of Paackland', 'City of Lomark', 'Nav 1', 'Nav 2', 'Ghoti Preserve', 'Exit East', 'Nav C', \"Wrasse Beds\", \"Don Limpet Preserve\",\"Nemo Preserve\",\"Tuna Shelf\")\ngeo_data_labels_1 &lt;- geo_data_1 %&gt;%\n  filter(id %in% label_ids)\n\n# Set plot size (for RStudio or other environments that support resizing)\noptions(repr.plot.width = 10, repr.plot.height = 8)\n\n# Geographical plot with labels\nggplot() +\n  geom_sf(data = geo_data_labels_1, aes(geometry = geometry, color = geo_data_labels_1$Marked)) +\n  geom_text(data = geo_data_labels_1 , aes(x = Longitude, y = Latitude, label = id), size = 2, color = \"black\", fontface = \"bold\") +\n  scale_color_manual(values = c(\"Suspicious\" = \"red\", \"Legitimate\" = \"blue\")) +\n  labs(title = \"Geographical Plot of roachrobberdb6 Activities\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 16),  # Enlarge title\n        legend.title = element_text(size = 12),  # Enlarge legend title\n        legend.text = element_text(size = 10),  # Enlarge legend text\n        axis.text = element_text(size = 10),  # Enlarge axis text\n        axis.title = element_text(size = 12))  # Enlarge axis title\n\n\n\n\n\n\n\n\n\n\n2.5. Suspicious Trajectories\nIn this section, we conduct an analysis of vessel trajectories to identify suspicious activities, particularly focusing on the operations of SouthSeafood Express Corp.\nTo begin, we extract transponder ping data, which provides information on vessel movements. We preprocess this data, assigning numeric values to locations and filtering out irrelevant areas such as Haacklee, Himark, Port Grove, Lomark, Paackland, and South Paackland. some interesting findings.\n\n\nShow the code\ndata &lt;- transponder_ping_df %&gt;%\n  mutate(date =ping_date,\n         start_time = time,\n         vessel = vessel_id,\n         company = vessel_company) %&gt;% \n  group_by(vessel) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  arrange(start_time) %&gt;%\n  filter(date &gt;= as.Date(\"2035-05-01\") & date &lt;= as.Date(\"2035-05-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n\nAfter preprocessing, we plot the trajectories of two vessels, “snappersnatcher7be” and “roachrobberdb6,” using ggplot. In the ggplot visualization, we showcase the vessels’ paths over time, along with location labels and customized color coding for each vessel. ggrepel was used to ensure that the labels not overlap.\n\n\nShow the code\ncombined_data &lt;- data %&gt;%\n  filter(vessel %in% c(\"snappersnatcher7be\", \"roachrobberdb6\")) %&gt;%\n  arrange(vessel, date)\n\n# Create the combined plot for all vessels\nggplot(combined_data, aes(x = date, y = location_num, group = vessel)) +\n  # Highlight co-occurrences\n  geom_point(combined_data = data %&gt;% group_by(date, location_num) %&gt;% filter(n() &gt; 1), \n             aes(x = date, y = location_num), color = \"black\", size = 6, shape = 21, fill = \"red\") +\n  # Original points\n  geom_point(aes(color = vessel, fill = vessel), size = 4, shape = 21, show.legend = TRUE) +\n  # Paths with arrows\n  geom_path(aes(color = vessel, linetype = vessel), size = 1, \n            arrow = arrow(type = \"closed\", length = unit(0.3, \"cm\")), show.legend = FALSE) +\n  scale_y_continuous(breaks = unique(data$location_num), labels = unique(data$location)) +\n  labs(title = \"Tainamarine Fishing Co's Vessel Trajectories Over Time\",\n       x = \"Date\",\n       y = \"Location\",\n       color = \"Vessel\",\n       fill = \"Vessel\",\n       linetype = \"Vessel\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.text = element_text(size = 8),\n        legend.key.width = unit(1, \"lines\"),\n        legend.key.height = unit(1, \"lines\"), # Control the height of the legend keys\n        legend.position = \"right\",\n        legend.spacing.y = unit(0.5, \"cm\")) + # Increase vertical spacing between legend items\n  guides(fill = guide_legend(override.aes = list(shape = 21, size = 4)))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant Observations\n\nThrough this visualization, we discerned a notable trend: both vessels frequently intersect at Nav C. This observation suggests a potential area for further investigation into the activities of SouthSeafood Express Corp. The consistent intersection of these vessels raises questions about the nature of their interactions at this location. This finding prompts us to delve deeper into the activities and operations of SouthSeafood Express Corp, as it may indicate coordinated movements or potential transshipment activities between the vessels. Further scrutiny of these intersecting points could uncover crucial insights into the company’s operational strategies and shed light on any illicit activities that may be occurring.\n\n\n\nIn the following section, we utilize several packages to prepare and process the data. We primarily use the sf package for handling spatial data, the dplyr package for data manipulation, and the ggplot2 package for data visualization. Additionally, we employ the tmap package to create interactive thematic maps.\nHere’s a summary of the technical steps:\nData Validation and Joining: We validate the geometries of the geographical data and join the node data with the geographical data based on the location identifier.\nConversion to sf Object: We convert the resulting data frame into an sf object using the st_as_sf function from the sf package.\nCoordinates Extraction: We extract coordinates for plotting the trajectories of the vessels “snappersnatcher7be” and “roachrobberdb6” separately using the st_coordinates function.\nData Combination: We combine the data for both vessels into a single data frame using the bind_rows function from the dplyr package.\n\n\nShow the code\n# Validate geometries\ngeo_data &lt;- geo_data %&gt;%\n  st_make_valid()\n\n# Join node data\nmc2_nodes_geo &lt;- data %&gt;%\n  left_join(geo_data, by = c(\"location\" = \"id\"))\n\n# Convert the resulting data frame to sf object\nmc2_nodes_geo_sf &lt;- st_as_sf(mc2_nodes_geo)\n\n# Extract coordinates for plotting for geometries\nsnappersnatcher7be_sf &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2]) %&gt;%\n  filter(vessel == \"snappersnatcher7be\")\n\nroachrobberdb6_sf &lt;- mc2_nodes_geo_sf %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2]) %&gt;%\n  filter(vessel == \"roachrobberdb6\")\n\n# Combine data for both vessels\ncombined_sf &lt;- bind_rows(snappersnatcher7be_sf, roachrobberdb6_sf)\n\n\nTmap Mode Setting: We set the tmap mode to “plot” using the tmap_mode function from the tmap package.\nMap Creation with tmap: We create a thematic map using tmap functions such as tm_shape, tm_borders, and tm_symbols. This map includes borders around each shape, symbols for nodes, and a watercolor style background.\nPlot Creation with ggplot: We create a ggplot with the geom_sf function to plot the geographical data, geom_path to plot the vessel trajectories, and geom_text to add labels to the plot. We also customize the plot aesthetics such as colors and legend titles using functions like scale_color_manual and labs.\n\n\nShow the code\n# Set tmap mode\ntmap_mode(\"plot\")\n\ngeo_data &lt;- st_as_sf(geo_data, coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\n\n# Create the ggplot with the legend for vessels\nggplot() +\n  geom_sf(data = geo_data, aes(geometry = geometry), color = \"black\", size = 0.5, fill = NA) +  # Plot borders\n  geom_point(data = combined_sf, aes(x = Longitude, y = Latitude, color = vessel), size = 3) +  # Plot points\n  geom_path(data = combined_sf, aes(x = Longitude, y = Latitude, color = vessel, group = vessel), size = 1) +  # Plot paths\n  geom_text(data = combined_sf, aes(x = Longitude, y = Latitude, label = location), size = 3, vjust = -1) +  # Add labels\n  scale_color_manual(values = c(\"snappersnatcher7be\" = \"green\", \"roachrobberdb6\" = \"blue\")) +  # Colors for different vessels\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"SouthSeafood Express Corp Vessel Trajectories\", color = \"Vessel\") +  # Add legend title\n  coord_sf() +  # Use coord_sf for spatial data\n  theme_minimal()  # Mi\n\n\n\n\n\n\n\n2.6, Insights from Visualisations\n\n\n\n\n\n\nNote\n\n\n\nSuspicious Movement and Catch Contents of SouthSeafood Express Corp\n\nMovement Patterns:\nThe vessel “snappersnatcher7be” shows frequent visits to suspicious locations such as “Nav 1” (17 occurrences) and “Nav 2” (7 occurrences), which are near “Ghoti Preserve”.\nThe visualization illustrates a significant number of transshipment events involving vessels associated with “SouthSeafood Express Corp.” These events, occurring over a period of time, indicate a pattern of coordinated activities suggestive of illicit practices.The plotted data reveals a consistent trend of transshipment occurrences over time, which deviates significantly from normal maritime operations. The frequency and pattern of these events suggest deliberate efforts to transfer goods between vessels, potentially for illegal purposes such as smuggling or avoiding regulatory oversight.\nCatch Contents:\nThe vessel “snappersnatcher7be” is suspected of carrying cargo such as “Wrasse/Labridae n.refert” which is found only in “Ghoti Preserve” , “Wrasse Beds” and “Nemo Reef.” However, our visualisation reveals that it does not venture near “Nemo Reef” and it spends an equal amount of time at “Wrasse Beds” and locations near “Ghoti Preserve”\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTiming and Locations of Illegal Fishing Activities for SouthSeafood Express Corp\n\nTimeframe of Illegal Activities:\nAround May 8th, “snappersnatcher7be” is likely involved in suspicious cargo activities involving “Wrasse/Labridae n.refert”. Hence, we suspect it conducted illegal fishing in the month previous.\nLocations of Illegal Fishing:\nThe vessel’s frequent visits to “Nav 1” and “Nav 2” suggest these locations are hotspots for illegal activities.\nThese locations are close to “Ghoti Preserve”, a region known for fish species like “Wrasse/Labridae n.refert”.\n\n\n\n::: callout-note Suspicious vessel tragejctories found likely to indicate transshipping\n\nThe trajectories of both vessels belonging to SouthSeafood Express Corp appear to intersect at specific points in time, particularly at Nav C. This presents a compelling indication of transshipment taking place."
  },
  {
    "objectID": "Project/Investigations.html#task-3.",
    "href": "Project/Investigations.html#task-3.",
    "title": "Investigations",
    "section": "Task 3.",
    "text": "Task 3.\nLooking for similar patterns as SouthSeafood Express Corp\n\n3.1 Visualisation for comparison between SouthSeaFood Vessels with Others\nAs observed, SouthSeaFood has been spending an unusual amount of time in specific locations, such as Nav C, Nav 3, and Ghoti Preserve. This has been traced back to their illegal fishing activities. Using the visualization we developed in RShiny as shown below, users can now gain deeper insights into different fishing regions and identify suspicious activities based on dwell time, similar to our earlier observations.\n\n\n\n\n\n\n\n3.2 Top 10 vessels with highest Dwell time in Ghoti Preserve\nNow Lets investigate the arrival of piscisosseusb6d in City of Paackland in November\n{target=“_blank”}\nLooking for dwell time in Ghoti Preserve, as piscisosseusb6d is only found in Ghoti Preserve and hence is a protected species.\n\n\nShow the code\n# Specify hardcoded city and month\nhardcoded_city &lt;- \"Ghoti Preserve\"\nselected_month &lt;- \"Nov\"\n\n# Extract year and month\ntransponder_ping_day_sum_df$year &lt;- year(transponder_ping_day_sum_df$ping_date)\ntransponder_ping_day_sum_df$month &lt;- month(transponder_ping_day_sum_df$ping_date, label = TRUE)\n\n# Summarize total dwell time for each vessel in each city and month\nmonthly_summary_df &lt;- transponder_ping_day_sum_df %&gt;%\n  group_by(year, month, location, vessel_id, vessel_type,vessel_company) %&gt;%\n  summarise(total_dwell_time = sum(total_dwell_time), .groups = 'drop') %&gt;%\n  arrange(location, month)\n\n# Filter to keep only top 5 vessels by dwell time for each city and month\ntop_vessels_df &lt;- monthly_summary_df %&gt;%\n  group_by(year, month, location) %&gt;%\n  slice_max(order_by = total_dwell_time, n = 10, with_ties = FALSE)\n\n\n\n# Filter the data for the hardcoded city and selected month\nfiltered_data &lt;- top_vessels_df %&gt;%\n  filter(location == hardcoded_city, month == selected_month) %&gt;%\n  arrange(desc(total_dwell_time))\n\n# Ensure only top 5 vessels are selected in case of any discrepancy\nfiltered_data &lt;- head(filtered_data, 10)\n\n# Create the Plotly plot\nplot &lt;- plot_ly(filtered_data, y = ~vessel_id, x = ~total_dwell_time, type = 'bar', orientation = 'h',\n                text = ~paste(\"Vessel ID:\", vessel_id, \"&lt;br&gt;Vessel Company:\", vessel_company,\"&lt;br&gt;vessel_type:\", vessel_type),\n                hoverinfo = 'text') %&gt;%\n  layout(title = paste(\"Top 10 Vessels in\", hardcoded_city, \"for\", selected_month),\n         yaxis = list(title = \"Vessel ID\"),\n         xaxis = list(title = \"Total Dwell Time (hours)\"),\n         barmode = 'stack')\n\n# Display the plot\nplot\n\n\n\n\n\n\nInsights:\n\nbrillbandit0a1,tunataker80c seems to be spending considerable amount of time in Ghoti preserve and is a suspect\n\n\n\n\n\n\n\nNote\n\n\n\nConclusion\n\nAs per above study,South Sea food seems to have performed illegal fishing at Wrasse beds and seems to also have performed transhipment to evade detection.\nWe are able to use similar patterns for detecting illegal fishing by other vessels.\nUsing all mechanism for detection provided above, it will be possible to watch out for anomalies and then plot path to detect illegal fishing.\n\n\n\n\n\n3.3. Visualization for Detecting Suspicious Fishing Vessels Based on Dwell Time in Ecological Preserves and Other Areas\nSimilarly, we have developed a visualization in RShiny to highlight the top 10 companies exhibiting unusually long dwell times in specific fishing spots, potentially indicating involvement in illegal fishing activities. Users will be able to derive insights by interacting with the widget to analyse with regards to the various locations across selected months."
  },
  {
    "objectID": "Project/Investigations.html#task-4",
    "href": "Project/Investigations.html#task-4",
    "title": "Investigations",
    "section": "Task 4",
    "text": "Task 4\nFishing behaviours after SouthSeafood Express Corp was caught"
  },
  {
    "objectID": "Project/Investigations.html#identifying-new-companies",
    "href": "Project/Investigations.html#identifying-new-companies",
    "title": "Investigations",
    "section": "4.1. Identifying New companies",
    "text": "4.1. Identifying New companies\nIn this section, we recreate the data and transshipment_data by processing the dataframe (transponder_ping_df) to analyze transshipment activities of vessels, this time for a larger date range. We aim to split the data into two periods: before and after SouthSeafood Express Corp was caught, likely around May 16, 2035.\nThe goal is to identify new companies involved in transshipment activities after the catch date by comparing the companies from both periods, highlighting potential new entrants to transshipment following the crackdown on SouthSeafood Express Corp.\n\n\n\n\n\n\nNote\n\n\n\nOther considerations\nHowver, since it is unlikely that companies restart illegal operations immediately after they are caught, we set the cutoff date to two months after SouthSeafood Express Corp was caught instead as 2035-07-12.\n\n\n\n\nShow the code\ndata &lt;- transponder_ping_df %&gt;%\n  mutate(date =ping_date,\n         start_time = time,\n         vessel = vessel_id,\n         company = vessel_company) %&gt;% \n  group_by(vessel) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  arrange(start_time) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  filter(date &gt;= as.Date(\"2035-02-01\") & date &lt;= as.Date(\"2035-10-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n\n\n# Step 2: Identify transshipment points\nexcluded_locations &lt;- c(\"Haacklee\", \"Himark\", \"Port Grove\", \"Lomark\", \"Paackland\", \"South Paackland\")\n\ntransshipment_data &lt;- data %&gt;%\n  filter(!location %in% excluded_locations) %&gt;%\n  group_by(company, date, location) %&gt;%\n  summarise(vessels_at_location = n_distinct(vessel), .groups = 'drop') %&gt;%\n  filter(vessels_at_location &gt; 1)\n\n\n\n# Filter transshipment data after the date when SouthSeafood Express Corp was caught\nafter_catch_date_and2months &lt;- transshipment_data %&gt;%\n  filter(date &gt;= as.Date(\"2035-07-12\"))  # Adjust the date as per your data\n\n# Identify unique companies involved in transshipment after the catch date\nunique_companies_after_catch &lt;- after_catch_date_and2months %&gt;%\n  distinct(company)\n\n# Filter transshipment data before the catch date\nbefore_catch_date_and2months &lt;- transshipment_data %&gt;%\n  filter(date &lt; as.Date(\"2035-07-11\"))  # Adjust the date as per your data\n\n# Check if any of the companies after the catch date are new\nnew_companies &lt;- unique_companies_after_catch %&gt;%\n  filter(!company %in% before_catch_date_and2months$company)\n\n# Print new companies starting transshipment after SouthSeafood Express Corp was caught\nprint(new_companies)\n\n\n# A tibble: 2 × 1\n  company               \n  &lt;chr&gt;                 \n1 Tainamarine Fishing Co\n2 Taylor-Sawyer"
  },
  {
    "objectID": "Project/Investigations.html#investigating-behaviours-of-new-companies",
    "href": "Project/Investigations.html#investigating-behaviours-of-new-companies",
    "title": "Investigations",
    "section": "4.2. Investigating behaviours of New companies",
    "text": "4.2. Investigating behaviours of New companies\n\n\nShow the code\n# Step 1: Filter transshipment data for the new vessels found\nnew_vessels_transshipment &lt;- transshipment_data %&gt;%\n  filter(company %in% new_companies$company) %&gt;%\n  group_by(company, date) %&gt;%\n  summarise(transshipment = n_distinct(date), .groups = 'drop') %&gt;%\n  group_by(company) %&gt;%\n  summarise(transshipment_days = n(), .groups = 'drop')\n\n\n\n\n# Create a column chart\nggplot(new_vessels_transshipment, aes(x = reorder(company, -transshipment_days), y = transshipment_days, fill = company)) +\n  geom_col() +\n  labs(title = \"Number of Transshipment Days by Company\",\n       x = \"Company\",\n       y = \"Transshipment Days\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "Project/Investigations.html#found-similarities-of-tainamarine-fishing-co-to-southseafood-express-corp",
    "href": "Project/Investigations.html#found-similarities-of-tainamarine-fishing-co-to-southseafood-express-corp",
    "title": "Investigations",
    "section": "4.3. Found Similarities of Tainamarine Fishing Co to SouthSeafood Express Corp",
    "text": "4.3. Found Similarities of Tainamarine Fishing Co to SouthSeafood Express Corp\nWe have identified two potential companies that might be the same entity as SouthSeafood Express Corp, which was caught red-handed and likely restarted their illegal fishing operations. These companies are Tainamarine Fishing Co and Taylor-Sawyer, both of which are found to be of suspicious of transhippment activities and also began operations within 2-3 months after SouthSeafood Express Corp was apprehended.\nAmong them, Tainamarine Fishing Co seemed to be the most likely suspect as the two vessels belonging to it swimmingsafely92d and posiedonsparadise7e6 possesses the same tonnage and length_overall as snappersnatcher7be and roachrobberdb6 respectively.\n\n\nShow the code\ninfo &lt;- nodes_df %&gt;%\n  filter(company %in% c(\"Tainamarine Fishing Co\", \"SouthSeafood Express Corp\"))\n\n# Select the relevant columns for tonnage and length_overall\ninfo %&gt;%\n  select(id, company, tonnage, length_overall)\n\n\n# A tibble: 4 × 4\n  id                   company                   tonnage length_overall\n  &lt;chr&gt;                &lt;chr&gt;                       &lt;dbl&gt;          &lt;dbl&gt;\n1 snappersnatcher7be   SouthSeafood Express Corp     100             20\n2 swimmingsafely92d    Tainamarine Fishing Co        100             20\n3 roachrobberdb6       SouthSeafood Express Corp   11700            130\n4 posiedonsparadise7e6 Tainamarine Fishing Co      11700            130\n\n\nIn the next section, we proceeded further to investigate Tainamarine Fishing Co by plotting its vessel trajectories over time. This in turn led to some interesting findings.\n\n\nShow the code\ndata &lt;- transponder_ping_df %&gt;%\n  mutate(date =ping_date,\n         start_time = time,\n         vessel = vessel_id,\n         company = vessel_company) %&gt;% \n  group_by(vessel) %&gt;%\n  mutate(end_time = lead(start_time)) %&gt;%\n  arrange(start_time) %&gt;%\n  filter(date &gt;= as.Date(\"2035-08-05\") & date &lt;= as.Date(\"2035-08-10\"))%&gt;%\n  ungroup() %&gt;%\n  select(date, start_time, end_time, location, vessel,company)\n\n# Remove rows where end_time is NA (last observation for each vessel)\ndata &lt;- data %&gt;% filter(!is.na(end_time))%&gt;% filter(!is.na(company))\n\n# Now you have start_time and end_time calculated for each vessel\n\n# Assign numeric values to locations for plotting purposes \ndata$location_factor &lt;- as.factor(data$location) \ndata$location_num &lt;- as.numeric(data$location_factor)\n\n  \ncombined_data &lt;- data %&gt;%\n  filter(company == \"Tainamarine Fishing Co\")\n\n# Create the combined plot for all vessels\nggplot(combined_data, aes(x = date, y = location_num, group = vessel)) +\n  # Highlight co-occurrences\n  geom_point(combined_data = data %&gt;% group_by(date, location_num) %&gt;% filter(n() &gt; 1), \n             aes(x = date, y = location_num), color = \"black\", size = 6, shape = 21, fill = \"red\") +\n  # Original points\n  geom_point(aes(color = vessel, fill = vessel), size = 4, shape = 21, show.legend = TRUE) +\n  # Paths with arrows\n  geom_path(aes(color = vessel, linetype = vessel), size = 1, \n            arrow = arrow(type = \"closed\", length = unit(0.3, \"cm\")), show.legend = FALSE) +\n  scale_y_continuous(breaks = unique(data$location_num), labels = unique(data$location)) +\n  labs(title = \"Tainamarine Fishing Co's Vessel Trajectories Over Time\",\n       x = \"Date\",\n       y = \"Location\",\n       color = \"Vessel\",\n       fill = \"Vessel\",\n       linetype = \"Vessel\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.text = element_text(size = 8),\n        legend.key.width = unit(1, \"lines\"),\n        legend.key.height = unit(1, \"lines\"), # Control the height of the legend keys\n        legend.position = \"right\",\n        legend.spacing.y = unit(0.5, \"cm\")) + # Increase vertical spacing between legend items\n  guides(fill = guide_legend(override.aes = list(shape = 21, size = 4)))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant Observations\nFrom the visualization below, it seems that Tainamarine Fishing Co’s vessel trajectories is very similar to SouthSeafood Express Corp vessels in that they tend to co-occur at Nav C too.\n\n\n\n\nShow the code\n# Group the data by company and vessel\n\n# Join node data\nmc2_nodes_geo &lt;- combined_data %&gt;%\n  left_join(geo_data, by = c(\"location\" = \"id\"))\n\n# Convert the resulting data frame to sf object\nmc2_nodes_geo_sf &lt;- st_as_sf(mc2_nodes_geo)\n\n\ngrouped_data &lt;- mc2_nodes_geo_sf %&gt;%\n  filter(company == \"Tainamarine Fishing Co\") %&gt;%  \n  group_by(company, vessel) %&gt;%\n  mutate(Longitude = st_coordinates(st_centroid(geometry))[, 1],\n         Latitude = st_coordinates(st_centroid(geometry))[, 2])\n\n# Create a palette of colors\ncolors &lt;- rainbow(length(unique(grouped_data$vessel)))\n\n# Create a ggplot with the legend for vessels\nggplot() +\n  geom_sf(data = geo_data, aes(geometry = geometry), color = \"black\", size = 2, fill = NA) +  # Plot borders\n  geom_path(data = grouped_data, aes(x = Longitude, y = Latitude, color = vessel, group = vessel), size = 1) +  # Plot paths with different colors for each vessel\n  geom_point(data = grouped_data, aes(x = Longitude, y = Latitude, color = vessel), size = 3) +  # Plot points\n  geom_text(data = grouped_data, aes(x = Longitude, y = Latitude, label = location), size = 3, vjust = -1) +  # Add labels\n  scale_color_manual(values = colors) +  # Assign colors to vessels\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Tainamarine Fishing Co's Vessel Trajectories\", color = \"Vessel\") +  # Add legend title\n  coord_sf() +  # Use coord_sf for spatial data\n  theme_minimal()  # Minimal theme\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nConclusion\nFrom the visualization below, it seems that Tainamarine Fishing Co’s vessel trajectories is very similar to SouthSeafood Express Corp vessels and is very likely the same entity which was caught fishing illegally earlier.\nThis is in addition to the other similarities mentioned earlier:\n\nNewly established company, 2 months afterSouthSeafood Express Corp was caught\nVessels that have the exact tonnage and length_overall of SouthSeafood Express Corp\nCo-occurence at Nav C"
  },
  {
    "objectID": "Project/Investigations.html#comparing-dwell-time-before-and-after-southseafoodcorp-was-caught",
    "href": "Project/Investigations.html#comparing-dwell-time-before-and-after-southseafoodcorp-was-caught",
    "title": "Investigations",
    "section": "4.4. Comparing dwell time before and after SouthSeaFoodCorp was caught",
    "text": "4.4. Comparing dwell time before and after SouthSeaFoodCorp was caught\nWe have also designed visualizations in RShiny to compare dwell times of fishing vessels before and after the capture of SouthSeaFood Corp, which helps to analyze the potential impacts on the fishing patterns of existing companies.\nThe goal is to reveal any shifts in fishing behaviors that may have occurred due to the crackdown on SouthSeaFood Corp, providing insights into broader trends and potential adjustments in fishing practices."
  },
  {
    "objectID": "Project/Investigations.html#comparing-cargo-transactions-before-and-after-southseafood-was-caught",
    "href": "Project/Investigations.html#comparing-cargo-transactions-before-and-after-southseafood-was-caught",
    "title": "Investigations",
    "section": "4.5. Comparing Cargo Transactions before and after SouthSeaFood was caught",
    "text": "4.5. Comparing Cargo Transactions before and after SouthSeaFood was caught\nAdditionally, we created RShiny visualizations to compare cargo transactions from before and after the capture of SouthSeaFood Corp, aiming to analyze how this event might have affected the fishing patterns of other companies. By analyzing cargo transaction data from periods before and after SouthSeaFood Corp’s capture, we are able to explore whether there have been changes in the types and volumes of fish being transported."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ocean Watch Tower",
    "section": "",
    "text": "This is a Quarto Website demonstrating Project Work for ISSS608 - Visual Analytics and Applications. This website addresses problem pertaining to 2024 Vast Challenge Mini Challenge 2.\nLinks below:\n\n2024 VAST Challenge\nProject Github"
  },
  {
    "objectID": "Project/Proposal.html",
    "href": "Project/Proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "2024 VAST Challenge \nhttps://vast-challenge.github.io/2024/MC2.html \n\n\n   Visual Analytics for Monitoring and Preventing Illegal Fishing Activities in Oceanus \n\n\n\nOceanus the island nation’s economy thrives on its fishing industry. The recent illegal fishing scandal involving SouthSeafood Express Corp has not only disrupted this vital sector but has also exposed significant gaps in monitoring and regulating fishing activities. By harnessing the power of visual analytics, this project aims to transform raw data into actionable insights, to unearth hidden patterns and to create a system capable of safeguarding Oceanus against future illegal activities. \n\n\n\nThis project addresses the critical challenge of detecting and predicting illegal fishing operations in Oceanus.  \nThe lack of accurate port records has led to a significant gap in tracking the true source and distribution of fish, making it difficult to enforce regulations and ensure sustainability.  \nThis project aims to fill these critical gaps by developing advanced visual analytics tools that can effectively integrate and analyze diverse data sources, offering a more reliable solution to monitor and combat illegal fishing activities.” \n\n\n\nhttps://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-022-00331-z \nThe study focuses on analyzing the global liner shipping network through various network representations and methodologies. The authors address the limitations of previous approaches which used shortest paths in fully connected undirected graphs, which could misrepresent the actual connectivity and paths in the liner shipping service route data. Instead, they propose and evaluate three different representations of the network: directed co-route graph, undirected co-route graph, and the path graph. \nKey innovations in the study include the development of a new method for constructing minimum-route paths from liner shipping data, which provides a more accurate reflection of route connectivity and distances than previous models. The researchers also introduce a modified betweenness centrality measure called route betweenness, which they use to analyze the network’s structure and the roles of various nodes and edges more effectively. \nhttps://link.springer.com/chapter/10.1007/978-3-030-61852-0_10 \nThe study investigates why certain ports are better connected than others. It explores the hierarchical nature of the network. Various measures of node connectivity are employed, all of which underscore an uneven distribution of traffic across the network. \nThe research delves into how cargo specialization or diversity influences the network’s structure. This aspect is analyzed through the lenses of multiplexity and assortativity, assessing whether nodes (ports) tend to diversify their activities or specialize. The analysis is conducted across two main layers—cargo and bulk—with findings indicating that larger ports and their connections tend to show greater diversification. \nThe final area of investigation focuses on the geographical patterns that underlie the distribution of maritime flows. The study examines how physical distance affects connectivity and the formation of subnetworks within the overall network. \n\n\n\nWe plan to analyze illegal fishing behavior and identify the anomalies in vessel movement and behavior through the R Shiny Web app. The application will have the following tabs: \n\nVessel Movement: A tab that can visually indicate the path of a vessel historically. This can help identify any seasonal trends or deviations of a vessel from its usual path. \n\n\n\nCargo and Vessel Matching: Matching the cargo visually to a vessel, the fish it contains, the date of delivery, and the city it was delivered to. This can be analyzed by the construction of a knowledge graph. \n\n\n\nSouthSeaFoodCorp Vessels: Suspicious behavior of SouthSeaFoodCorp Express Vessels. Comparison of their vessel trajectory and fishing contents with other vessels. \n\n\n\nIllegal activities after SouthSeaFoodCorp Express was caught: Behavior of the Shipping community after SouthSeaFoodCorp Express was caught. \n\nCreation of Knowledge Graph to identify Cargo Vessel Match: \nWe have Cargo Transaction Records, Vessel Transponder Ping Records, Harbor Report Records and details of vessels and Locations. We can use this information to develop a possible cargo vessel mapping. Then we plan to do some data transformation to represent this visually through a Knowledge Graph. \nVessel Movement: \nWe can identify anomalies in vessel movement using DBSCAN Clustering. We already have coordinates of the cities and navigation points. Plotting out these can help us track vessel movements with time, identify seasonality and anomalies. \nKnowledge Graph for zooming in on SouthSeaFoodCorp Vessels: \nWe can plot a graph to inspect activity of SouthSeaFoodCorp Vessels. This can be used to identify the fishing done, the timelines, the places of fishing and possibly isolate out the illegal activities. Once the event of SouthSeaFoodCorp being caught is identified we plan to do a temporal analysis for analyzing how other organizations changed their behavior. \nProjected timeline: \nThe entire project will be done in 4 weeks. \nWeek1: \nMatching cargo to the vessels \nDigging deeper into SouthSeaFoodCorp Vessels \nWeek 2: \nPlotting Vessel Movements to identify seasonality and anomalies.  \nPinpointing the time when SouthSeaFoodCorp was caught and analyzing activities of other companies after that. \nWeek 3: \nIncorporating codes into R Shiny \nIdentifying vessels showing behavior like SouthSeaFoodCorp vessels \nWeek 4: \nTouch up R Shiny dashboard layouts. \nFocus on completing activities remaining from Week 1, 2 & 3. \nElaborate on the kind of illegal activities the vessels are engaging in. \n\n\n\nDiagram 1: EDA to understand the usual fishing spots and regions that are frequented by the suspected vessels \nSouthSeafood Express Corp’s Activities \n\nDiagram 2: Which locations should it not be at? \n\nDiagram 3: Merging geospatial analysis with network analysis \n\nSnappersnatcher7be appears to be frequently visiting areas Nav1 and Nav2, which are located around the Ghoti Preserve. Given the type of fish it typically catches, it should not be near these locations. \nDiagram 4: The other vessel does not seem to demonstrate suspicious activities \n\n\n\n\nSuccessful implementation of this project will deter illegal fishing practices through advanced detection capabilities, making it easier to implement regulations and promoting sustainable fishing practices."
  },
  {
    "objectID": "Project/Proposal.html#proposal-document-for-visual-analytics-project",
    "href": "Project/Proposal.html#proposal-document-for-visual-analytics-project",
    "title": "Project Proposal",
    "section": "",
    "text": "2024 VAST Challenge \nhttps://vast-challenge.github.io/2024/MC2.html \n\n\n   Visual Analytics for Monitoring and Preventing Illegal Fishing Activities in Oceanus \n\n\n\nOceanus the island nation’s economy thrives on its fishing industry. The recent illegal fishing scandal involving SouthSeafood Express Corp has not only disrupted this vital sector but has also exposed significant gaps in monitoring and regulating fishing activities. By harnessing the power of visual analytics, this project aims to transform raw data into actionable insights, to unearth hidden patterns and to create a system capable of safeguarding Oceanus against future illegal activities. \n\n\n\nThis project addresses the critical challenge of detecting and predicting illegal fishing operations in Oceanus.  \nThe lack of accurate port records has led to a significant gap in tracking the true source and distribution of fish, making it difficult to enforce regulations and ensure sustainability.  \nThis project aims to fill these critical gaps by developing advanced visual analytics tools that can effectively integrate and analyze diverse data sources, offering a more reliable solution to monitor and combat illegal fishing activities.” \n\n\n\nhttps://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-022-00331-z \nThe study focuses on analyzing the global liner shipping network through various network representations and methodologies. The authors address the limitations of previous approaches which used shortest paths in fully connected undirected graphs, which could misrepresent the actual connectivity and paths in the liner shipping service route data. Instead, they propose and evaluate three different representations of the network: directed co-route graph, undirected co-route graph, and the path graph. \nKey innovations in the study include the development of a new method for constructing minimum-route paths from liner shipping data, which provides a more accurate reflection of route connectivity and distances than previous models. The researchers also introduce a modified betweenness centrality measure called route betweenness, which they use to analyze the network’s structure and the roles of various nodes and edges more effectively. \nhttps://link.springer.com/chapter/10.1007/978-3-030-61852-0_10 \nThe study investigates why certain ports are better connected than others. It explores the hierarchical nature of the network. Various measures of node connectivity are employed, all of which underscore an uneven distribution of traffic across the network. \nThe research delves into how cargo specialization or diversity influences the network’s structure. This aspect is analyzed through the lenses of multiplexity and assortativity, assessing whether nodes (ports) tend to diversify their activities or specialize. The analysis is conducted across two main layers—cargo and bulk—with findings indicating that larger ports and their connections tend to show greater diversification. \nThe final area of investigation focuses on the geographical patterns that underlie the distribution of maritime flows. The study examines how physical distance affects connectivity and the formation of subnetworks within the overall network. \n\n\n\nWe plan to analyze illegal fishing behavior and identify the anomalies in vessel movement and behavior through the R Shiny Web app. The application will have the following tabs: \n\nVessel Movement: A tab that can visually indicate the path of a vessel historically. This can help identify any seasonal trends or deviations of a vessel from its usual path. \n\n\n\nCargo and Vessel Matching: Matching the cargo visually to a vessel, the fish it contains, the date of delivery, and the city it was delivered to. This can be analyzed by the construction of a knowledge graph. \n\n\n\nSouthSeaFoodCorp Vessels: Suspicious behavior of SouthSeaFoodCorp Express Vessels. Comparison of their vessel trajectory and fishing contents with other vessels. \n\n\n\nIllegal activities after SouthSeaFoodCorp Express was caught: Behavior of the Shipping community after SouthSeaFoodCorp Express was caught. \n\nCreation of Knowledge Graph to identify Cargo Vessel Match: \nWe have Cargo Transaction Records, Vessel Transponder Ping Records, Harbor Report Records and details of vessels and Locations. We can use this information to develop a possible cargo vessel mapping. Then we plan to do some data transformation to represent this visually through a Knowledge Graph. \nVessel Movement: \nWe can identify anomalies in vessel movement using DBSCAN Clustering. We already have coordinates of the cities and navigation points. Plotting out these can help us track vessel movements with time, identify seasonality and anomalies. \nKnowledge Graph for zooming in on SouthSeaFoodCorp Vessels: \nWe can plot a graph to inspect activity of SouthSeaFoodCorp Vessels. This can be used to identify the fishing done, the timelines, the places of fishing and possibly isolate out the illegal activities. Once the event of SouthSeaFoodCorp being caught is identified we plan to do a temporal analysis for analyzing how other organizations changed their behavior. \nProjected timeline: \nThe entire project will be done in 4 weeks. \nWeek1: \nMatching cargo to the vessels \nDigging deeper into SouthSeaFoodCorp Vessels \nWeek 2: \nPlotting Vessel Movements to identify seasonality and anomalies.  \nPinpointing the time when SouthSeaFoodCorp was caught and analyzing activities of other companies after that. \nWeek 3: \nIncorporating codes into R Shiny \nIdentifying vessels showing behavior like SouthSeaFoodCorp vessels \nWeek 4: \nTouch up R Shiny dashboard layouts. \nFocus on completing activities remaining from Week 1, 2 & 3. \nElaborate on the kind of illegal activities the vessels are engaging in. \n\n\n\nDiagram 1: EDA to understand the usual fishing spots and regions that are frequented by the suspected vessels \nSouthSeafood Express Corp’s Activities \n\nDiagram 2: Which locations should it not be at? \n\nDiagram 3: Merging geospatial analysis with network analysis \n\nSnappersnatcher7be appears to be frequently visiting areas Nav1 and Nav2, which are located around the Ghoti Preserve. Given the type of fish it typically catches, it should not be near these locations. \nDiagram 4: The other vessel does not seem to demonstrate suspicious activities \n\n\n\n\nSuccessful implementation of this project will deter illegal fishing practices through advanced detection capabilities, making it easier to implement regulations and promoting sustainable fishing practices."
  }
]